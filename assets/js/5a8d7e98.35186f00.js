"use strict";(self.webpackChunkoverture_schema=self.webpackChunkoverture_schema||[]).push([[96],{2425:(e,a,t)=>{t.d(a,{Z:()=>o});var n=t(7294),l=t(6010);const r={tabItem:"tabItem__kUE"};function o(e){let{children:a,hidden:t,className:o}=e;return n.createElement("div",{role:"tabpanel",className:(0,l.Z)(r.tabItem,o),hidden:t},a)}},4762:(e,a,t)=>{t.d(a,{Z:()=>T});var n=t(7462),l=t(7294),r=t(6010),o=t(2466),i=t(6550),s=t(1980),p=t(7392),m=t(12);function u(e){return function(e){return l.Children.map(e,(e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:a}=e;return!!a&&"object"==typeof a&&"value"in a}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:a,label:t,attributes:n,default:l}}=e;return{value:a,label:t,attributes:n,default:l}}))}function c(e){const{values:a,children:t}=e;return(0,l.useMemo)((()=>{const e=a??u(t);return function(e){const a=(0,p.l)(e,((e,a)=>e.value===a.value));if(a.length>0)throw new Error(`Docusaurus error: Duplicate values "${a.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[a,t])}function d(e){let{value:a,tabValues:t}=e;return t.some((e=>e.value===a))}function k(e){let{queryString:a=!1,groupId:t}=e;const n=(0,i.k6)(),r=function(e){let{queryString:a=!1,groupId:t}=e;if("string"==typeof a)return a;if(!1===a)return null;if(!0===a&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:a,groupId:t});return[(0,s._X)(r),(0,l.useCallback)((e=>{if(!r)return;const a=new URLSearchParams(n.location.search);a.set(r,e),n.replace({...n.location,search:a.toString()})}),[r,n])]}function N(e){const{defaultValue:a,queryString:t=!1,groupId:n}=e,r=c(e),[o,i]=(0,l.useState)((()=>function(e){let{defaultValue:a,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(a){if(!d({value:a,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${a}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return a}const n=t.find((e=>e.default))??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:a,tabValues:r}))),[s,p]=k({queryString:t,groupId:n}),[u,N]=function(e){let{groupId:a}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(a),[n,r]=(0,m.Nk)(t);return[n,(0,l.useCallback)((e=>{t&&r.set(e)}),[t,r])]}({groupId:n}),g=(()=>{const e=s??u;return d({value:e,tabValues:r})?e:null})();(0,l.useLayoutEffect)((()=>{g&&i(g)}),[g]);return{selectedValue:o,selectValue:(0,l.useCallback)((e=>{if(!d({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);i(e),p(e),N(e)}),[p,N,r]),tabValues:r}}var g=t(2389);const h={tabList:"tabList_fbd4",tabItem:"tabItem_v5XY"};function b(e){let{className:a,block:t,selectedValue:i,selectValue:s,tabValues:p}=e;const m=[],{blockElementScrollPositionUntilNextRender:u}=(0,o.o5)(),c=e=>{const a=e.currentTarget,t=m.indexOf(a),n=p[t].value;n!==i&&(u(a),s(n))},d=e=>{let a=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=m.indexOf(e.currentTarget)+1;a=m[t]??m[0];break}case"ArrowLeft":{const t=m.indexOf(e.currentTarget)-1;a=m[t]??m[m.length-1];break}}a?.focus()};return l.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":t},a)},p.map((e=>{let{value:a,label:t,attributes:o}=e;return l.createElement("li",(0,n.Z)({role:"tab",tabIndex:i===a?0:-1,"aria-selected":i===a,key:a,ref:e=>m.push(e),onKeyDown:d,onClick:c},o,{className:(0,r.Z)("tabs__item",h.tabItem,o?.className,{"tabs__item--active":i===a})}),t??a)})))}function f(e){let{lazy:a,children:t,selectedValue:n}=e;const r=(Array.isArray(t)?t:[t]).filter(Boolean);if(a){const e=r.find((e=>e.props.value===n));return e?(0,l.cloneElement)(e,{className:"margin-top--md"}):null}return l.createElement("div",{className:"margin-top--md"},r.map(((e,a)=>(0,l.cloneElement)(e,{key:a,hidden:e.props.value!==n}))))}function v(e){const a=N(e);return l.createElement("div",{className:(0,r.Z)("tabs-container",h.tabList)},l.createElement(b,(0,n.Z)({},e,a)),l.createElement(f,(0,n.Z)({},e,a)))}function T(e){const a=(0,g.Z)();return l.createElement(v,(0,n.Z)({key:String(a)},e))}},2228:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>m,contentTitle:()=>s,default:()=>k,frontMatter:()=>i,metadata:()=>p,toc:()=>u});var n=t(7462),l=(t(7294),t(3905)),r=(t(2403),t(4762)),o=t(2425);const i={title:"Build a Basemap"},s="Building a Basemap from Overture Data",p={unversionedId:"getting_started/build-a-map",id:"getting_started/build-a-map",title:"Build a Basemap",description:"Placeholder",source:"@site/docs/getting_started/build-a-map.mdx",sourceDirName:"getting_started",slug:"/getting_started/build-a-map",permalink:"/getting_started/build-a-map",draft:!1,tags:[],version:"current",frontMatter:{title:"Build a Basemap"},sidebar:"docs",previous:{title:"Locally (DuckDB)",permalink:"/accessing-the-data/locally"}},m={},u=[{value:"Placeholder &lt; Map Here &gt;",id:"placeholder--map-here-",level:3},{value:"&lt; Map Here &gt;",id:"-map-here-",level:3},{value:"&lt; Map Here &gt;",id:"-map-here--1",level:3},{value:"&lt; Map Here &gt;",id:"-map-here--2",level:3},{value:"Step 1: Download the Data",id:"step-1-download-the-data",level:3},{value:"Part 2: Make a map with maplibre",id:"part-2-make-a-map-with-maplibre",level:3}],c={toc:u},d="wrapper";function k(e){let{components:a,...t}=e;return(0,l.kt)(d,(0,n.Z)({},c,t,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"building-a-basemap-from-overture-data"},"Building a Basemap from Overture Data"),(0,l.kt)("h3",{id:"placeholder--map-here-"},"Placeholder < Map Here >"),(0,l.kt)("h3",{id:"-map-here-"},"< Map Here >"),(0,l.kt)("h3",{id:"-map-here--1"},"< Map Here >"),(0,l.kt)("h3",{id:"-map-here--2"},"< Map Here >"),(0,l.kt)("h3",{id:"step-1-download-the-data"},"Step 1: Download the Data"),(0,l.kt)("p",null,"Because Overture data is released as a single collection of data in a cloud-native format (parquet), interfacing with the data through a service that can take advantage of the cloud-native properties of the data."),(0,l.kt)("p",null,"The queries presented here are meant to run in Amazon Athena against the ",(0,l.kt)("inlineCode",{parentName:"p"},"overture_2023_10_19_alpha_0")," table, as set up in ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/OvertureMaps/data#accessing-overture-maps-data-1"},"these instructions"),"."),(0,l.kt)("p",null,"Below are different queries for each theme that extract only the relevant attributes for each feature within a specific bounding box. In this case, Seattle, Washington, USA. Each Athena query produces a ",(0,l.kt)("inlineCode",{parentName:"p"},"CSV")," file which can be turned into ",(0,l.kt)("inlineCode",{parentName:"p"},"GeoJSON")," file using ",(0,l.kt)("a",{parentName:"p",href:"https://duckdb.org/"},"DuckDB")," and then run through ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/felt/tippecanoe"},"tippecanoe")," to produce a ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/protomaps/PMTiles"},(0,l.kt)("inlineCode",{parentName:"a"},"PMTiles"))," archive:"),(0,l.kt)(r.Z,{queryString:"athena-query",mdxType:"Tabs"},(0,l.kt)(o.Z,{value:"buildings",label:"Buildings",default:!0,mdxType:"TabItem"},(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Athena query to produce ",(0,l.kt)("inlineCode",{parentName:"p"},"buildings.csv"),":"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT class,\n    TRY(FILTER(names.common, x -> x.language = 'local')[1].value) as local_name,\n    height,\n    level,\n    CAST(sources AS JSON) as sources,\n    ST_ASTEXT(ST_GeomFromBinary(geometry)) as geometry_wkt\nFROM overture_2023_10_19_alpha_0\nWHERE theme = 'buildings' AND type = 'building'\n    AND bbox.minX > -122.679404 AND bbox.maxX < -121.978275\n    AND bbox.minY > 47.360619 AND bbox.maxY < 47.786336\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Use DuckDB to convert ",(0,l.kt)("inlineCode",{parentName:"p"},"buildings.csv")," into a GeoJSONSeq file."),(0,l.kt)("details",null,(0,l.kt)("summary",null,"DuckDB Query ( ",(0,l.kt)("code",null,"SQL")," )"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"COPY (\n    SELECT\n        \"class\",\n        \"local_name\",\n        \"height\",\n        \"level\",\n        \"sources\",\n        ST_GeomFromText(geometry_wkt) as geometry\n    FROM read_csv('csv/buildings.csv', header=True,\n        COLUMNS={\n            'class':'VARCHAR',\n            'local_name':'VARCHAR',\n            'height':'DOUBLE',\n            'level':'VARCHAR',\n            'sources':'VARCHAR',\n            'geometry_wkt':'VARCHAR'\n        }\n    )\n    ) TO 'geojson/buildings.geojsonseq'\nWITH (FORMAT GDAL, DRIVER 'GeoJSONSeq');\n")))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Run ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/felt/tippecanoe"},"tippecanoe")," to produce a ",(0,l.kt)("inlineCode",{parentName:"p"},"pmtiles")," archive from ",(0,l.kt)("inlineCode",{parentName:"p"},"buildings.geojsonseq")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"tippecanoe -o tiles/buildings.pmtiles -Z13 -z13 -l buildings -P geojson/buildings.geojsonseq\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Tippecanoe flag explanation"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-o tiles/buildings.pmtiles")," is our output file."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-Z13")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"-z13")," will produce a tileset starting at zoom 13 and going up to zoom 13 (so only 1 zoom level)."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-l buildings"),' names the layer "buildings"'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-P")," allows tippecanoe to read the file in parallel. Since we created a GeoJSON sequence file instead of a single GeoJSON Feature Collection, tippecanoe can process the input data more efficiently.")))))),(0,l.kt)(o.Z,{value:"roads",label:"Roads",default:!0,mdxType:"TabItem"},(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Athena query to produce ",(0,l.kt)("inlineCode",{parentName:"p"},"roads.csv"),":"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    level,\n    JSON_EXTRACT_SCALAR(road, '$.class') AS road_class,\n    JSON_EXTRACT_SCALAR(road, '$.roadNames.common[0].value') AS road_name,\n    sources[1].dataset AS source,\n    ST_ASTEXT(ST_GeomFromBinary(geometry)) as geometry_wkt\nFROM overture_2023_10_19_alpha_0\nWHERE theme = 'transportation' AND type = 'segment'\n    AND bbox.minX > -122.679404 AND bbox.maxX < -121.978275\n    AND bbox.minY > 47.360619 AND bbox.maxY < 47.786336\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Use DuckDB to convert ",(0,l.kt)("inlineCode",{parentName:"p"},"roads.csv")," into a GeoJSONSeq file."),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"COPY (\n    SELECT\n        road_class as class,\n        road_name as name,\n        level,\n        ST_GeomFromText(geometry_wkt) as geometry\n    FROM 'csv/roads.csv'\n    ) TO 'geojson/roads.geojsonseq'\nWITH (FORMAT GDAL, DRIVER 'GeoJSONSeq');\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Run ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/felt/tippecanoe"},"tippecanoe")," to produce a ",(0,l.kt)("inlineCode",{parentName:"p"},"pmtiles")," archive from ",(0,l.kt)("inlineCode",{parentName:"p"},"roads.geojsonseq")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"tippecanoe -o tiles/roads.pmtiles -Z10 -B10 -z13 -l roads -P geojson/roads.geojsonseq\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Tippecanoe flag explanation"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-o tiles/roads.pmtiles")," is our output file."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-Z10")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"-z13")," will produce a tileset starting at zoom 10 and going up to zoom 13."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-B10")," will ensure that all featuers are present from zoom level 10."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-l roads"),' names the layer "roads"'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-P")," allows tippecanoe to read the file in parallel. Since we created a GeoJSON sequence file instead of a single GeoJSON Feature Collection, tippecanoe can process the input data more efficiently.")))))),(0,l.kt)(o.Z,{value:"places",label:"Places",default:!0,mdxType:"TabItem"},(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Athena query to produce ",(0,l.kt)("inlineCode",{parentName:"p"},"places.csv"),":"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    TRY(\n        FILTER(names.common, x->x.language = 'local') [ 1 ].value\n    ) as local_name,\n   categories.main as category,\n   ROUND(confidence,2) as confidence,\n   TRY(websites[1]) AS url,\n   TRY(addresses[1]) AS address,\n   sources[1] as source,\n   ST_ASTEXT(ST_GeomFromBinary(geometry)) as geometry_wkt\nFROM overture_2023_10_19_alpha_0\nWHERE theme = 'places' AND type = 'place'\n    AND bbox.minX > -122.679404 AND bbox.maxX < -121.978275\n    AND bbox.minY > 47.360619 AND bbox.maxY < 47.786336\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Use DuckDB to convert ",(0,l.kt)("inlineCode",{parentName:"p"},"places.csv")," into a GeoJSONSeq file."),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"COPY (\nSELECT\n    local_name as name,\n    confidence, category, url, address, source,\n    ST_GeomFromText(geometry_wkt) as geometry\nFROM 'csv/places.csv'\n) TO 'geojson/places.geojsonseq'\nWITH (FORMAT GDAL, DRIVER 'GeoJSONSeq', SRS 'EPSG:4326');\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Run ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/felt/tippecanoe"},"tippecanoe")," to produce a ",(0,l.kt)("inlineCode",{parentName:"p"},"pmtiles")," archive from ",(0,l.kt)("inlineCode",{parentName:"p"},"places.geojsonseq")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"tippecanoe -fo tiles/places.pmtiles -Z13 -z13 -l places -P geojson/places.geojsonseq\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Tippecanoe flag explanation"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-fo tiles/places.pmtiles")," is our output file, which we can overwrite (f) if it exists."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-Z13")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"-z13")," will produce a tileset starting at zoom 13 and going up to zoom 13 (so only 1 zoom level)."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-l places"),' names the layer "buildings"'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-P")," allows tippecanoe to read the file in parallel. Since we created a GeoJSON sequence file instead of a single GeoJSON Feature Collection, tippecanoe can process the input data more efficiently.")))))),(0,l.kt)(o.Z,{value:"water",label:"Water",default:!0,mdxType:"TabItem"},(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Athena query to produce ",(0,l.kt)("inlineCode",{parentName:"p"},"water.csv"),":"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    subType,\n    class,\n    TRY(FILTER(names.common, x -> x.language = 'local')[1].value) as name,\n    height,\n    ST_ASTEXT(ST_GeomFromBinary(geometry)) as geometry_wkt\nFROM overture_2023_10_19_alpha_0\nWHERE theme = 'base' AND type = 'water' AND subType in ('ocean','lake','river')\n    AND bbox.minX > -122.679404 AND bbox.maxX < -121.978275\n    AND bbox.minY > 47.360619 AND bbox.maxY < 47.786336\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Use DuckDB to convert ",(0,l.kt)("inlineCode",{parentName:"p"},"water.csv")," into a GeoJSON file (using GeoJSON instead of GeoJSONSeq purely as an example)."),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"COPY (\n    SELECT\n        subType, class, name,\n        ST_GeomFromText(geometry_wkt) as geometry\n    FROM read_csv('csv/water.csv', auto_detect=True)\n    ) TO 'geojson/water.geojson'\nWITH (FORMAT GDAL, DRIVER 'GeoJSON', SRS 'EPSG:4326');\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Run ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/felt/tippecanoe"},"tippecanoe")," to produce a ",(0,l.kt)("inlineCode",{parentName:"p"},"pmtiles")," archive from ",(0,l.kt)("inlineCode",{parentName:"p"},"water.geojson")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"tippecanoe -o tiles/water.pmtiles -Z8 -z10 -l buildings geojson/water.geojson\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Tippecanoe flag explanation"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-o tiles/water.pmtiles")," is our output file."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-Z8")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"-z13")," will produce a tileset starting at zoom 8 and going up to zoom 12."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-l water"),' names the layer "buildings"')))))),(0,l.kt)(o.Z,{value:"placenames",label:"Placenames",default:!0,mdxType:"TabItem"},(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Athena query to produce ",(0,l.kt)("inlineCode",{parentName:"p"},"placenames.csv"),":"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    subType,\n    localityType,\n    TRY(FILTER(names.common, x -> x.language = 'local')[1].value) as local_name,\n    adminLevel,\n    ST_ASTEXT(ST_CENTROID(ST_GeomFromBinary(geometry))) as geometry_wkt\nFROM overture_2023_10_19_alpha_0\nWHERE theme = 'admins' AND type = 'locality'\n    AND bbox.minX > -122.679404 AND bbox.maxX < -121.978275\n    AND bbox.minY > 47.360619 AND bbox.maxY < 47.786336\n")))),(0,l.kt)("ol",{start:2},(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Use DuckDB to convert ",(0,l.kt)("inlineCode",{parentName:"p"},"placenames.csv")," into a GeoJSON file."),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"COPY (\n   SELECT\n       localityType,\n       local_name as name,\n       adminlevel,\n       ST_GeomFromText(geometry_wkt) as geometry\n   FROM read_csv_auto('csv/placenames.csv')\n) TO 'geojson/placenames.geojson'\nWITH (FORMAT GDAL, DRIVER 'GeoJSON', SRS 'EPSG:4326');\n"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Run ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/felt/tippecanoe"},"tippecanoe")," to produce a ",(0,l.kt)("inlineCode",{parentName:"p"},"pmtiles")," archive from ",(0,l.kt)("inlineCode",{parentName:"p"},"placenames.geojson")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"tippecanoe -o tiles/placenames.pmtiles -Z5 -z10 -l buildings geojson/placenames.geojson\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Tippecanoe flag explanation"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-o tiles/buildings.pmtiles")," is our output file."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-Z5")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"-z10")," will produce a tileset starting at zoom 5 and going up to zoom 13."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-l placenames"),' names the layer "buildings"')))))),(0,l.kt)(o.Z,{value:"landuse",label:"Land Use",default:!0,mdxType:"TabItem"},(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Query the buildings theme using Amazon Athena and download the results as a CSV file, ",(0,l.kt)("inlineCode",{parentName:"p"},"buildings.csv"),":"),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Athena Query ( ",(0,l.kt)("code",null,"SQL")," )"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT class,\n    TRY(FILTER(names.common, x -> x.language = 'local')[1].value) as local_name,\n    height,\n    level,\n    CAST(sources AS JSON) as sources,\n    ST_ASTEXT(ST_GeomFromBinary(geometry)) as geometry_wkt\nFROM overture_2023_10_19_alpha_0\nWHERE theme = 'buildings'\n    AND type = 'building'\n    AND bbox.minX > -122.679404\n    AND bbox.maxX < -121.978275\n    AND bbox.minY > 47.360619\n    AND bbox.maxY < 47.786336\n")))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Use DuckDB to convert ",(0,l.kt)("inlineCode",{parentName:"p"},"buildings.csv")," into a GeoJSONSeq file."),(0,l.kt)("details",null,(0,l.kt)("summary",null,"DuckDB Query ( ",(0,l.kt)("code",null,"SQL")," )"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-sql"},"COPY (\n    SELECT\n        \"class\",\n        \"local_name\",\n        \"height\",\n        \"level\",\n        \"sources\",\n        ST_GeomFromText(geometry_wkt) as geometry\n    FROM read_csv('csv/buildings.csv', header=True,\n        COLUMNS={\n            'class':'VARCHAR',\n            'local_name':'VARCHAR',\n            'height':'DOUBLE',\n            'level':'VARCHAR',\n            'sources':'VARCHAR',\n            'geometry_wkt':'VARCHAR'\n        }\n    )\n    ) TO 'geojson/buildings.geojsonseq'\nWITH (FORMAT GDAL, DRIVER 'GeoJSONSeq');\n")))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},"Run ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/felt/tippecanoe"},"tippecanoe")," to produce a ",(0,l.kt)("inlineCode",{parentName:"p"},"pmtiles")," archive from ",(0,l.kt)("inlineCode",{parentName:"p"},"buildings.geojsonseq")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"tippecanoe -o tiles/placenames.pmtiles -Z13 -z13 -l buildings -P geojson/buildings.geojsonseq\n")),(0,l.kt)("details",null,(0,l.kt)("summary",null,"Tippecanoe flag explanation"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-o tiles/buildings.pmtiles")," is our output file."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-Z13")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"-z13")," will produce a tileset starting at zoom 13 and going up to zoom 13 (so only 1 zoom level)."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-l buildings"),' names the layer "buildings"'),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"-P")," allows tippecanoe to read the file in parallel. Since we created a GeoJSON sequence file instead of a single GeoJSON Feature Collection, tippecanoe can process the input data more efficiently."))))))),(0,l.kt)("h3",{id:"part-2-make-a-map-with-maplibre"},"Part 2: Make a map with maplibre"))}k.isMDXComponent=!0}}]);