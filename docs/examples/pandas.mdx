---
title: Overture + Pandas
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


In this example, we'll show you how to use [Pandas](http://pandas.pydata.org/) and [GeoPandas](https://geopandas.org/en/stable/index.html) to handle and manipulate Overture data.


## Requirements
You can view and download the complete notebook on Notebook Sharing Space.

To follow along, you'll need to have [JupyterLab or Jupyter Notebook](https://jupyter.org/) running and the following dependencies installed:
- [Pandas](https://pandas.pydata.org/)
- [GeoPandas](https://geopandas.org/en/stable/index.html)
- [Shapely](https://shapely.readthedocs.io/en/stable/index.html) 
- [DuckDB](https://duckdb.org/), [DuckDB spatial extension](https://duckdb.org/docs/extensions/spatial.html), and [DuckDB AWS extension](https://duckdb.org/docs/extensions/aws.html)
- [JupySQL](https://jupysql.ploomber.io/en/latest/quick-start.html) (optional)
- [duckdb-engine](https://github.com/Mause/duckdb_engine) (optional)

First, let's import our toolkit. We're using [Pandas](http://pandas.pydata.org/), a Python package for in-memory data manipulation, and [GeoPandas](https://geopandas.org/en/stable/index.html), a Python library that extends Pandas to allow spatial operations on geometric types. Shapely will help us handle the geometries, and DuckDB is the tool we'll use to fetch only the data we need from Overture's GeoParquet files stored in an S3 bucket.

```python
# import our toolkit
import pandas as pd
import geopandas as gpd
from shapely import wkt
import duckdb
```
Next, we'll install and load DuckDB extensions to work with spatial data and connect to AWS.

```python
%sql INSTALL spatial;
%sql INSTALL httpfs;
%sql LOAD spatial;
%sql LOAD httpfs;
%sql SET s3_region='us-west-2'
```
The DuckDB documentation offers tips and examples for [running DuckDB queries in Jupyter notebooks](https://duckdb.org/docs/guides/python/jupyter.html). 

```python 
# no need to import duckdb_engine, jupysql will auto-detect driver 
# load (or reload) jupysql Jupyter extension to create SQL cells
%reload_ext sql

# configure cell output
%config SqlMagic.autopandas = True
%config SqlMagic.feedback = False
%config SqlMagic.displaycon = False

# set connection string
%sql duckdb:///:memory: --alias duckdb-sqlalchemy
```

Now we're going to extract county-level data for Pennsylvania from Overture's divisions theme. DuckDB allows up to pull a slice of Overture data from hundreds of gigabytes worth of data stored in GeoParquet files in the cloud.

Note: the magic %%sql command turns a notebook cell into a SQL cell. We'll store our query results in a Pandas DataFrame.

```python
%%sql overture_counties <<
SELECT 
    id,
    division_id, 
    names.primary AS primary_name,
    ST_AsText(ST_GeomFromWKB(geometry)) as geometry 
FROM 
    read_parquet('s3://overturemaps-us-west-2/release/2024-07-22.0/theme=divisions/type=division_area/*', filename=true, hive_partitioning=1)
WHERE 
    subtype = 'county'
    AND country = 'US'
    AND region = 'US-PA';
```

Before we move on, let's deal with the geometry we pulled out of Overture's GeoParquet file. Remember that geometry columns in GeoParquet are stored as well-known binary (WKB). In our query, we transformed that geometry into text, and now we need to turn it into a Shapely geometry to get it into our GeoDataFrame. Here's how we do that.

```python
overture_counties['geometry'] = overture_counties['geometry'].apply(wkt.loads)

# dataframe to geodataframe, set crs
overture_counties_gdf = gpd.GeoDataFrame(
    overture_counties
    , geometry='geometry', crs="EPSG:4326"
)
```
Voila! Pennsylvania counties. 

```python
overture_counties_gdf.plot(facecolor="pink", edgecolor="red", lw=0.7)
```

## Next steps

- Want to skip the GeoJSON part and take advantage of using a fully binary pipeline to grab and work with Overture data? Check out our lonboard tutorial to speed things up and work with larger data. 
- Want to make a map with the data? Check out our QGIS, kepler.gl, and PMTiles tutorials. 

